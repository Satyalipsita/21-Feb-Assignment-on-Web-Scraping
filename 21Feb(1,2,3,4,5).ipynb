{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Q-1: Web scraping is an automatic method to obtain large amounts of data from websites. \nMost of this data is unstructured data in an HTML format which is then converted into structured data \nin a spreadsheet or a database so that it can be used in various applications. \n web scraping is conducted in the following domains\n    1.Price Monitoring\n    2.Market Researc\n    3.News Monitoring\n    4.Sentiment Analysis\n    5.Email Marketing\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Q-2: Different types of scrapping\n    MANUAL SCRAPING-Copy Paste \n    AUTOMATED SCRAPPING\n      1:Html parsing\n      2:Dom Parsing\n      3:VERTICAL AGGREGATION\n      4: XPATH\n      5:GOOGLE SHEETS \n      6:TEXT PATTERN MATCHING",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Q-3:Beautiful Soup provides simple methods for navigating, \nsearching, and modifying a parse tree in HTML, XML files.\nIt transforms a complex HTML document into a tree of Python objects. \nIt also automatically converts the document to Unicode, \nso you don’t have to think about encodings.\nThis tool not only helps you scrape but also to clean the data.\nBeautiful Soup supports the HTML parser included in Python’s standard library, \nbut it also supports several third-party Python parsers like lxml or hml5lib.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#q-4:Flask is a lightweight framework to build websites.\nWe'll use this to parse our collected data and display it as HTML in a new HTML file. \nThe requests module allows us to send http requests to the website we want to scrape. \nThe first line imports the Flask class and the render_template method from the flask library.\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Q-5: Code pipeline-\nAWS CodePipeline is a continuous delivery service you can use to model, \nvisualize, and automate the steps required to release your software. \nYou can quickly model and configure the different stages of a software release process. \nCodePipeline automates the steps required to release your software changes continuously\n\nAWS Elastic Beanstalk :\n     it is a service to rapidly deploy and scale web applications developed with\n        Java, . NET, PHP, Node. js, Python, Ruby, Go, and Docker on familiar servers such as Apache, \n        NGINX, Passenger, and IIS.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}